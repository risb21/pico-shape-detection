{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 08:12:03.249353: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-10 08:12:03.249456: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-10 08:12:03.366759: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-10 08:12:03.576235: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-10 08:12:05.256128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['circle', 'square', 'e_circle', 'e_square', 'triangle', 'e_triangle']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir(r\"./accelerometer_data/\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "# os.chdir(\"acc_py\")\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the e_circle directory\n",
      "In the e_square directory\n",
      "In the e_triangle directory\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic accelerometer data for three shapes: Circle, Square, Triangle\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples for each shape\n",
    "# num_samples = 101\n",
    "\n",
    "# Accelerometer data (x, y, z)\n",
    "# shapes = {}\n",
    "maxlen = 0\n",
    "rec_len = 0\n",
    "for shape in os.listdir():\n",
    "    if shape[0] != 'e':\n",
    "        continue\n",
    "    # shapes[shape] = 0\n",
    "    os.chdir(f\"./{shape}\")\n",
    "    print(f\"In the {shape} directory\")\n",
    "    for file in os.listdir():\n",
    "        rec_len = 0\n",
    "        with open(file, \"r\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            data = list(reader)[1:]\n",
    "            d_array = np.array(data, dtype = float)\n",
    "            # rec_len = d_array.shape[0]\n",
    "            maxlen = max(maxlen, d_array.shape[0])\n",
    "            # shapes[shape] = np.stack((shapes[shape], d_array))\n",
    "            # shapes[shape].append(d_array)\n",
    "        \n",
    "        # if rec_len <= 5 or rec_len > 85:\n",
    "        #     os.remove(file)\n",
    "        #     shapes[shape] += 1\n",
    "    # shapes[shape] = np.array(shapes[shape])\n",
    "\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "\n",
    "# print(shapes)\n",
    "\n",
    "print(maxlen)\n",
    "# print(shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the e_circle directory\n",
      "circle (101, 83, 3)\n",
      "In the e_square directory\n",
      "square (101, 83, 3)\n",
      "In the e_triangle directory\n",
      "triangle (101, 83, 3)\n"
     ]
    }
   ],
   "source": [
    "hist_data = []\n",
    "shapes = {}\n",
    "\n",
    "for shape in os.listdir():\n",
    "    if shape[0] != 'e':\n",
    "        continue\n",
    "    os.chdir(f\"./{shape}\")\n",
    "    print(f\"In the {shape} directory\")\n",
    "    shape = shape[2:]\n",
    "    for i, file in enumerate(os.listdir()):\n",
    "        with open(file, \"r\") as f:\n",
    "            try:\n",
    "                reader = csv.reader(f)\n",
    "                data = list(reader)[1:]\n",
    "                data.extend([['0.0' for _ in range(4)] for _ in range(83 - len(data))])\n",
    "                d_array = np.array(data, dtype = float)\n",
    "                d_array = d_array[:, 1:]\n",
    "                d_array.reshape((1, 83, 3))\n",
    "                # hist_data.append(d_array.shape[0])\n",
    "                if i == 0:\n",
    "                    shapes[shape] = d_array\n",
    "                else:\n",
    "                    shapes[shape] = np.append(shapes[shape], d_array)\n",
    "            except Exception as e:\n",
    "                os.chdir(\"..\")\n",
    "                raise e\n",
    "            \n",
    "    shapes[shape] = shapes[shape].reshape((101, 83, 3))\n",
    "    print(shape, shapes[shape].shape)\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "# shapes['e_circle'] = shapes['e_circle'].reshape((101, 83, 3))\n",
    "# print(shapes['e_circle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(hist_data, int(120/5), color = 'green', alpha = 0.7)\n",
    "plt.xlabel('Length of data')\n",
    "plt.ylabel('No. of recordings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "samples = 101\n",
    "\n",
    "# Combine data and labels\n",
    "data = np.vstack((shapes['circle'], shapes['square'], shapes['triangle']))\n",
    "labels = np.hstack((['circle'] * samples, ['square'] * samples, ['triangle'] * samples))\n",
    "labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.Input(shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "# model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "# model.add(SimpleRNN(64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 249)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                8000      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8691 (33.95 KB)\n",
      "Trainable params: 8691 (33.95 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "193/193 [==============================] - 2s 3ms/step - loss: 0.9656 - accuracy: 0.5233 - val_loss: 0.8063 - val_accuracy: 0.6735\n",
      "Epoch 2/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.6218 - accuracy: 0.7772 - val_loss: 0.7598 - val_accuracy: 0.7347\n",
      "Epoch 3/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.5062 - accuracy: 0.8031 - val_loss: 0.7249 - val_accuracy: 0.6735\n",
      "Epoch 4/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.4137 - accuracy: 0.8342 - val_loss: 0.7735 - val_accuracy: 0.6735\n",
      "Epoch 5/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.3541 - accuracy: 0.8653 - val_loss: 0.8347 - val_accuracy: 0.7143\n",
      "Epoch 6/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8653 - val_loss: 0.7556 - val_accuracy: 0.6939\n",
      "Epoch 7/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.3002 - accuracy: 0.8912 - val_loss: 0.7652 - val_accuracy: 0.7143\n",
      "Epoch 8/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.2449 - accuracy: 0.9067 - val_loss: 0.8865 - val_accuracy: 0.6939\n",
      "Epoch 9/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.2421 - accuracy: 0.8912 - val_loss: 0.7902 - val_accuracy: 0.7347\n",
      "Epoch 10/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.1940 - accuracy: 0.9223 - val_loss: 0.8028 - val_accuracy: 0.7347\n",
      "Epoch 11/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.1499 - accuracy: 0.9482 - val_loss: 0.8584 - val_accuracy: 0.7551\n",
      "Epoch 12/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.1424 - accuracy: 0.9430 - val_loss: 0.8337 - val_accuracy: 0.7551\n",
      "Epoch 13/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.1098 - accuracy: 0.9689 - val_loss: 0.9216 - val_accuracy: 0.7551\n",
      "Epoch 14/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0891 - accuracy: 0.9793 - val_loss: 1.0397 - val_accuracy: 0.7551\n",
      "Epoch 15/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0904 - accuracy: 0.9689 - val_loss: 0.9616 - val_accuracy: 0.7551\n",
      "Epoch 16/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0486 - accuracy: 0.9948 - val_loss: 1.0155 - val_accuracy: 0.7551\n",
      "Epoch 17/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0662 - accuracy: 0.9741 - val_loss: 1.0339 - val_accuracy: 0.6939\n",
      "Epoch 18/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.1173 - accuracy: 0.9637 - val_loss: 1.0780 - val_accuracy: 0.6939\n",
      "Epoch 19/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9948 - val_loss: 1.0797 - val_accuracy: 0.7347\n",
      "Epoch 20/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0207 - accuracy: 0.9948 - val_loss: 1.1626 - val_accuracy: 0.7551\n",
      "Epoch 21/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0315 - accuracy: 0.9948 - val_loss: 1.2324 - val_accuracy: 0.7347\n",
      "Epoch 22/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0217 - accuracy: 0.9896 - val_loss: 1.1436 - val_accuracy: 0.7347\n",
      "Epoch 23/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 1.2232 - val_accuracy: 0.7347\n",
      "Epoch 24/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2204 - val_accuracy: 0.7551\n",
      "Epoch 25/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.2244 - val_accuracy: 0.7347\n",
      "Epoch 26/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1861 - val_accuracy: 0.7347\n",
      "Epoch 27/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2667 - val_accuracy: 0.7551\n",
      "Epoch 28/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3050 - val_accuracy: 0.7551\n",
      "Epoch 29/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2813 - val_accuracy: 0.7347\n",
      "Epoch 30/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3209 - val_accuracy: 0.7551\n",
      "Epoch 31/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3421 - val_accuracy: 0.7347\n",
      "Epoch 32/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3850 - val_accuracy: 0.7551\n",
      "Epoch 33/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3538 - val_accuracy: 0.7551\n",
      "Epoch 34/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 9.7499e-04 - accuracy: 1.0000 - val_loss: 1.3654 - val_accuracy: 0.7551\n",
      "Epoch 35/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 8.4428e-04 - accuracy: 1.0000 - val_loss: 1.4039 - val_accuracy: 0.7347\n",
      "Epoch 36/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 7.4237e-04 - accuracy: 1.0000 - val_loss: 1.3900 - val_accuracy: 0.7347\n",
      "Epoch 37/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 5.9259e-04 - accuracy: 1.0000 - val_loss: 1.4257 - val_accuracy: 0.7347\n",
      "Epoch 38/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 5.6912e-04 - accuracy: 1.0000 - val_loss: 1.4564 - val_accuracy: 0.7551\n",
      "Epoch 39/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 4.7021e-04 - accuracy: 1.0000 - val_loss: 1.4623 - val_accuracy: 0.7347\n",
      "Epoch 40/40\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 4.1905e-04 - accuracy: 1.0000 - val_loss: 1.5064 - val_accuracy: 0.7347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7ee01c37f710>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=40, batch_size=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      circle       0.85      0.85      0.85        20\n",
      "      square       0.79      0.83      0.81        18\n",
      "    triangle       0.82      0.78      0.80        23\n",
      "\n",
      "    accuracy                           0.82        61\n",
      "   macro avg       0.82      0.82      0.82        61\n",
      "weighted avg       0.82      0.82      0.82        61\n",
      "\n",
      "[[17  1  2]\n",
      " [ 1 15  2]\n",
      " [ 2  3 18]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Decode predictions\n",
    "# decoded_predictions = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# print(decoded_predictions)\n",
    "# print(y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "print(classification_report(y_pred, y_test, target_names=['circle', 'square', 'triangle']))\n",
    "print(confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: acc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: acc/assets\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "model.save(\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp77ggm_mk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp77ggm_mk/assets\n",
      "/home/risb/Desktop/acc_py/rnn/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-02-10 09:23:15.819858: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-02-10 09:23:15.819885: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-02-10 09:23:15.820049: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp77ggm_mk\n",
      "2024-02-10 09:23:15.820691: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-02-10 09:23:15.820702: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp77ggm_mk\n",
      "2024-02-10 09:23:15.822667: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-02-10 09:23:15.846666: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp77ggm_mk\n",
      "2024-02-10 09:23:15.855702: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 35653 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 18, % non-converted = 50.00 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import datetime\n",
    "\n",
    "random.seed(datetime.datetime.now().microsecond + datetime.datetime.now().second)\n",
    "\n",
    "model = keras.models.load_model(\"acc\")\n",
    "\n",
    "def repr_dataset():\n",
    "    data = shapes[random.choice(['circle', 'square', 'triangle'])][random.randint(0, 100)]\n",
    "    yield [np.float32(data)]\n",
    "\n",
    "tflite_name = \"acc_edge_small_int8.tflite\"\n",
    "\n",
    "tflite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_converter.representative_dataset = repr_dataset\n",
    "tflite_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "tflite_converter.inference_input_type = tf.uint8\n",
    "tflite_converter.inference_output_type = tf.uint8\n",
    "tflite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = tflite_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12608"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "open(tflite_name, 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_carray(hex_data, var: str) -> str:\n",
    "    c_str = ''\n",
    "\n",
    "    # Add header\n",
    "    c_str += '#pragma once\\n\\n'\n",
    "    c_str += 'const unsigned int ' + var + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "    c_str += 'const unsigned char ' + var + '[] = {\\n\\t'\n",
    "\n",
    "    for i, val in enumerate(hex_data):\n",
    "        c_str += f\"0x{val:02x}{',' if i+1 < len(hex_data) else ''}\"\n",
    "        if (i+1) % 100 == 0:\n",
    "            c_str += '\\n\\t'\n",
    "    \n",
    "    c_str += '\\n};\\n'\n",
    "\n",
    "    return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shape_model_int8.hpp', 'w') as f:\n",
    "    f.write(hex_to_carray(tflite_model, 'shape_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_2:0', 'index': 0, 'shape': array([ 1, 83,  3], dtype=int32), 'shape_signature': array([-1, 83,  3], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.015313724987208843, 124), 'quantization_parameters': {'scales': array([0.01531372], dtype=float32), 'zero_points': array([124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 14, 'shape': array([1, 3], dtype=int32), 'shape_signature': array([-1,  3], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.00390625, 0), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import datetime\n",
    "\n",
    "\n",
    "random.seed(datetime.datetime.now().microsecond + datetime.datetime.now().second)\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path='acc_edge_small_int8.tflite')\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# input details\n",
    "print(input_details)\n",
    "# output details\n",
    "print(output_details)\n",
    "\n",
    "# interpreter.set_tensor(input_details[0]['index'], np.float32(shapes['square'][random.randint(0, 100)].reshape((1, 83, 3))))\n",
    "# interpreter.invoke()\n",
    "\n",
    "# output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# print(output_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
